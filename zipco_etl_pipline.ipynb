{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8175d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ca7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://realty-mole-property-api.p.rapidapi.com/randomProperties\"\n",
    "\n",
    "querystring = {\"limit\":\"100000\"}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"64114f9223mshf6ee7f915c727eep1a5d9djsnef3a9270cef8\",\n",
    "\t\"x-rapidapi-host\": \"realty-mole-property-api.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "# print(response.json())\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# save data to json file\n",
    "filename = 'PropertyRecords.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f244e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into a DataFrame\n",
    "propertyrecords_df = pd.read_json('PropertyRecords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3393d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace NaN values with appropriate defaults or remove  row/columns as necessary\n",
    "propertyrecords_df.fillna({\n",
    "    'assessorID': 'Unknown',\n",
    "    'legalDescription': 'Not available',\n",
    "    'squareFootage': 0,\n",
    "    'subdivision': 'Not available',\n",
    "    'yearBuilt': 0,\n",
    "    'bathrooms': 0,\n",
    "    'lotSize': 0,\n",
    "    'propertyType': 'Unknown',\n",
    "    'lastSalePrice': 0,\n",
    "    'lastSaleDate': 'Not available',\n",
    "    'features': 'None',\n",
    "    'taxAssessment': 'Not available',\n",
    "    'owner': 'Unknown',\n",
    "    'propertyTaxes': 'Not available',\n",
    "    'bedrooms': 0,\n",
    "    'ownerOccupied': 0,\n",
    "    'zoning': 'Unknown',\n",
    "    'addressLine2': 'Not available',\n",
    "    'formattedAddres': 'Not available',\n",
    "    'county': 'Not available',\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6573239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create location Dimension\n",
    "location_dim = propertyrecords_df[['formattedAddress', 'city', 'state', 'zipCode', 'county', 'subdivision', 'longitude', 'latitude']].copy().drop_duplicates().reset_index(drop=True)\n",
    "location_dim['location_id'] =range(1, len(location_dim) + 1)\n",
    "location_dim = location_dim[['location_id', 'formattedAddress', 'city', 'state', 'zipCode', 'county', 'subdivision', 'longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8206541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sales Dimension\n",
    "sales_dim = propertyrecords_df[['lastSalePrice', 'lastSaleDate']].copy().drop_duplicates().reset_index(drop=True)\n",
    "sales_dim['sales_id'] =range(1, len(sales_dim) + 1)\n",
    "sales_dim = sales_dim[['sales_id', 'lastSalePrice', 'lastSaleDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d97f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create location Dimension\n",
    "property_type_dim = propertyrecords_df[['propertyType', 'zoning', 'bedrooms', 'bathrooms', 'squareFootage', 'lotSize', 'ownerOccupied']].copy().drop_duplicates().reset_index(drop=True)\n",
    "property_type_dim['property_type_id'] =range(1, len(property_type_dim) + 1)\n",
    "property_type_dim = property_type_dim[['property_type_id', 'propertyType', 'zoning', 'bedrooms', 'bathrooms', 'squareFootage', 'lotSize', 'ownerOccupied']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec098d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create location Dimension\n",
    "legal_description_dim = propertyrecords_df[['legalDescription', 'yearBuilt']].copy().drop_duplicates().reset_index(drop=True)\n",
    "legal_description_dim['legal_description_id'] =range(1, len(legal_description_dim) + 1)\n",
    "legal_description_dim = legal_description_dim[['legal_description_id', 'legalDescription', 'yearBuilt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5efc31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge operation to create the propertyrecords_df\n",
    "propertyrecords_df = propertyrecords_df.merge(location_dim, on=['formattedAddress', 'city', 'state', 'zipCode', 'county', 'subdivision', 'longitude', 'latitude'], how='left') \\\n",
    "    .merge(property_type_dim, on=['propertyType', 'zoning', 'bedrooms', 'bathrooms', 'squareFootage', 'lotSize', 'ownerOccupied'], how='left') \\\n",
    "    .merge(sales_dim, on=['lastSalePrice', 'lastSaleDate'], how='left') \\\n",
    "    .merge(legal_description_dim, on=['legalDescription', 'yearBuilt'], how='left')\n",
    "\n",
    "# Ensure 'location_id', 'property_type_id', and 'legal_description_id' exist in the merged DataFrame\n",
    "propertyrecords_df = propertyrecords_df[['location_id', 'sales_id','property_type_id', 'legal_description_id','bathrooms', 'squareFootage', 'lotSize', 'ownerOccupied']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e522deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_columns = ['location_id', 'sales_id','property_type_id', 'legal_description_id','bathrooms', 'squareFootage', 'lotSize', 'ownerOccupied']\n",
    "fact_table = propertyrecords_df[fact_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb4fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save created tables to a csv file\n",
    "\n",
    "# saving the created fact and dimension table to csv file\n",
    "location_dim.to_csv('location_dimension.csv', index = False)\n",
    "property_type_dim.to_csv('property_type_dimension.csv', index = False)\n",
    "sales_dim.to_csv('sales_dimension.csv', index = False)\n",
    "legal_description_dim.to_csv('legalDescription_dimension.csv', index = False)\n",
    "fact_table.to_csv('property_fact.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e74df311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Layer\n",
    "# develop a function to connect to pgadmin\n",
    "\n",
    "def get_db_connection():\n",
    "    connection = psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        database = 'zipco_agency',\n",
    "        user = 'postgres',\n",
    "        password = 'Favour@8282'\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "conn = get_db_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ef44f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create schema and tables\n",
    "def create_tables():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    create_table_query = '''\n",
    "    CREATE SCHEMA IF NOT EXISTS zipco;\n",
    "\n",
    "    DROP TABLE IF EXISTS zipco.location_dim CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.property_type_dim CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.legal_description_dim CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.sales_dim CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.fact_table CASCADE;\n",
    "    \n",
    "     \n",
    "    CREATE TABLE IF NOT EXISTS zipco.location_dim (\n",
    "        location_id SERIAL PRIMARY KEY,\n",
    "        formattedAddress VARCHAR(255),\n",
    "        city VARCHAR(100),\n",
    "        state VARCHAR(100),\n",
    "        zipcode INTEGER,\n",
    "        county VARCHAR(100),\n",
    "        subdivision VARCHAR(100),\n",
    "        longitude FLOAT,\n",
    "        latitude FLOAT\n",
    "    );\n",
    "    \n",
    "     CREATE TABLE IF NOT EXISTS zipco.property_type_dim (\n",
    "        property_type_id SERIAL PRIMARY KEY,\n",
    "        propertyType VARCHAR(255),\n",
    "        zoning VARCHAR(50),\n",
    "        bedrooms FLOAT,\n",
    "        bathrooms FLOAT,\n",
    "        squareFootage FLOAT,\n",
    "        lotSize FLOAT,\n",
    "        ownerOccupied VARCHAR(50)\n",
    "        \n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.sales_dim (\n",
    "        sales_id SERIAL PRIMARY KEY,\n",
    "        lastSalePrice FLOAT,  \n",
    "        lastSaleDate DATE\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.legal_description_dim (\n",
    "        legal_description_id SERIAL PRIMARY KEY,\n",
    "        legalDescription VARCHAR(255),\n",
    "        yearBuilt FLOAT  \n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.fact_table (\n",
    "        location_id INTEGER,\n",
    "        sales_id INTEGER,\n",
    "        property_type_id INTEGER,\n",
    "        legal_description_id INTEGER,\n",
    "        bathrooms FLOAT,\n",
    "        squareFootage FLOAT,\n",
    "        lotSize FLOAT,\n",
    "        ownerOccupied FLOAT,\n",
    "        FOREIGN KEY (location_id) REFERENCES zipco.location_dim(location_id),\n",
    "        FOREIGN KEY (sales_id) REFERENCES zipco.sales_dim(sales_id),\n",
    "        FOREIGN KEY (property_type_id) REFERENCES zipco.property_type_dim(property_type_id),\n",
    "        FOREIGN KEY (legal_description_id) REFERENCES zipco.legal_description_dim(legal_description_id)\n",
    "        \n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit() \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    \n",
    "create_tables() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63378383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to load the csv data into the database\n",
    "\n",
    "def load_data_from_csv_to_table(csv_path, table_name):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r', encoding = 'utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) # Skip the header row\n",
    "        for row in reader:\n",
    "            placeholders = ', '.join(['%s'] * len(row))\n",
    "            query = f'INSERT INTO {table_name} VALUES ({placeholders});'\n",
    "            cursor.execute(query, row)\n",
    "    conn.commit() \n",
    "    cursor.close()\n",
    "    conn.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e4ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data from csv file to location dimension table\n",
    "location_dim_csv_path = r'C:\\Users\\Acer\\zipco_estate\\location_dimension.csv'\n",
    "load_data_from_csv_to_table(location_dim_csv_path, 'zipco.location_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef7c6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data from csv file to Property Type dimension table\n",
    "property_type_dim_csv_path = r'C:\\Users\\Acer\\zipco_estate\\property_type_dimension.csv'\n",
    "load_data_from_csv_to_table(property_type_dim_csv_path, 'zipco.property_type_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59d7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data from csv file to legal description dimension table\n",
    "legal_description_dim_csv_path = r'C:\\Users\\Acer\\zipco_estate\\legalDescription_dimension.csv'\n",
    "load_data_from_csv_to_table(legal_description_dim_csv_path, 'zipco.legal_description_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef035fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to ignore the Not Available in the sales dimension table\n",
    "\n",
    "# create a function to load the csv data into the database\n",
    "\n",
    "def load_data_from_csv_to_sales_table(csv_path, table_name):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # define the columns name in sales_dim table\n",
    "    sale_dim_columns = ['sales_id', 'lastSalePrice', 'lastSaleDate']\n",
    "    \n",
    "    with open(csv_path, 'r', encoding = 'utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) # Skip the header row\n",
    "        \n",
    "        for row in reader:\n",
    "            # Convert empty strings (or 'Not Available' in the date to None(Null in SQL)\n",
    "            # row = [None if (cell == '' or cell == 'Not available') and col_name == 'lastSaledate' else cell for cell, col_name in zip(row, sale_dim_columns)]\n",
    "            row = [None if col_name == 'lastSaleDate' and (cell == '' or cell.lower() == 'not available') else cell for cell, col_name in zip(row, sale_dim_columns)]\n",
    "            placeholders = ', '.join(['%s'] * len(row))\n",
    "            query = f'INSERT INTO {table_name} VALUES ({placeholders});'\n",
    "            cursor.execute(query, row)\n",
    "    conn.commit() \n",
    "    cursor.close()\n",
    "    conn.close()  \n",
    "    \n",
    "\n",
    "\n",
    "# sales dimension table\n",
    "\n",
    "sales_dim_csv_path = r'C:\\Users\\Acer\\zipco_estate\\sales_dimension.csv'\n",
    "load_data_from_csv_to_sales_table(sales_dim_csv_path, 'zipco.sales_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "407a3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data from csv file to fact table table\n",
    "fact_table_csv_path = r'C:\\Users\\Acer\\zipco_estate\\property_fact.csv'\n",
    "load_data_from_csv_to_table(fact_table_csv_path, 'zipco.fact_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf6cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been loaded successfully into the respective schema and tables\n"
     ]
    }
   ],
   "source": [
    "print('All data has been loaded successfully into the respective schema and tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2784b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
